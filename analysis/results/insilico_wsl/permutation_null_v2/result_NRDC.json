{
  "ensembl": "ENSG00000078618",
  "symbol": "NRDC",
  "status": "failed",
  "error": "CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
  "traceback": "Traceback (most recent call last):\n  File \"/mnt/d/openclaw/intelligence-augmentation/analysis/permutation_null_v2_run_one.py\", line 93, in main\n    isp.perturb_data(\n  File \"/home/agent/.local/lib/python3.12/site-packages/geneformer/in_silico_perturber.py\", line 503, in perturb_data\n    self.isp_perturb_set(\n  File \"/home/agent/.local/lib/python3.12/site-packages/geneformer/in_silico_perturber.py\", line 646, in isp_perturb_set\n    full_perturbation_emb = get_embs(\n                            ^^^^^^^^^\n  File \"/home/agent/.local/lib/python3.12/site-packages/geneformer/emb_extractor.py\", line 167, in get_embs\n    torch.cuda.empty_cache()\n  File \"/home/agent/.local/lib/python3.12/site-packages/torch/cuda/memory.py\", line 280, in empty_cache\n    torch._C._cuda_emptyCache()\ntorch.AcceleratorError: CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
  "time_seconds": 479.944447517395
}